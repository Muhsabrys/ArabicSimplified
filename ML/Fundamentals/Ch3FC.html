<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Classification Concepts - Flashcards</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            margin: 0;
            padding: 20px;
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .container {
            max-width: 600px;
            width: 100%;
        }
        .flashcard {
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            min-height: 300px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            text-align: center;
            cursor: pointer;
            transition: transform 0.3s;
        }
        .flashcard:hover {
            transform: translateY(-5px);
        }
        .question {
            font-size: 20px;
            color: #333;
            line-height: 1.6;
        }
        .answer {
            font-size: 18px;
            color: #555;
            line-height: 1.6;
            display: none;
        }
        .controls {
            display: flex;
            justify-content: space-between;
            margin-top: 20px;
            gap: 10px;
        }
        button {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            background: #667eea;
            color: white;
            font-size: 16px;
            cursor: pointer;
            transition: background 0.3s;
        }
        button:hover {
            background: #5a67d8;
        }
        button:disabled {
            background: #cbd5e0;
            cursor: not-allowed;
        }
        .progress {
            text-align: center;
            color: white;
            margin-bottom: 20px;
            font-size: 18px;
        }
        .flip-hint {
            color: rgba(255,255,255,0.8);
            text-align: center;
            margin-top: 10px;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="progress">
            Card <span id="current">1</span> of <span id="total">0</span>
        </div>
        <div class="flashcard" onclick="flipCard()">
            <div class="question" id="question"></div>
            <div class="answer" id="answer"></div>
        </div>
        <div class="flip-hint">Click card to reveal answer</div>
        <div class="controls">
            <button onclick="previousCard()" id="prevBtn">Previous</button>
            <button onclick="flipCard()">Flip Card</button>
            <button onclick="nextCard()" id="nextBtn">Next</button>
        </div>
    </div>

    <script>
        // Improved flashcards focusing on classification concepts
        const flashcardsData = [
            // Core Concepts
            {
                "f": "What are the two most common supervised learning tasks?",
                "b": "Regression (predicting continuous values) and classification (predicting discrete classes or categories)."
            },
            {
                "f": "What is a binary classifier?",
                "b": "A classifier capable of distinguishing between exactly two classes (e.g., 'spam' vs 'not spam', 'positive' vs 'negative')."
            },
            {
                "f": "What is a multiclass (multinomial) classifier?",
                "b": "A classifier that can distinguish between more than two classes (e.g., classifying images into categories like cat, dog, bird, etc.)."
            },
            {
                "f": "What is a skewed dataset in classification?",
                "b": "A dataset where some classes are much more frequent than others (class imbalance), which can lead to misleading accuracy metrics."
            },
            
            // Confusion Matrix
            {
                "f": "What is a confusion matrix?",
                "b": "A table that shows the number of correct and incorrect predictions made by a classifier, broken down by actual class and predicted class."
            },
            {
                "f": "In a confusion matrix, what do rows and columns represent?",
                "b": "Each row represents an actual class, while each column represents a predicted class."
            },
            {
                "f": "What would a perfect classifier's confusion matrix look like?",
                "b": "It would have nonzero values only on the main diagonal (from top-left to bottom-right), indicating all predictions were correct."
            },
            {
                "f": "Define: True Positives (TP)",
                "b": "Instances of the positive class that were correctly classified as positive."
            },
            {
                "f": "Define: False Positives (FP)",
                "b": "Instances of the negative class that were incorrectly classified as positive (Type I error)."
            },
            {
                "f": "Define: False Negatives (FN)",
                "b": "Instances of the positive class that were incorrectly classified as negative (Type II error)."
            },
            {
                "f": "Define: True Negatives (TN)",
                "b": "Instances of the negative class that were correctly classified as negative."
            },
            
            // Performance Metrics
            {
                "f": "Why is accuracy often not the best metric for classification, especially with imbalanced datasets?",
                "b": "A classifier can achieve high accuracy by simply predicting the most frequent class for all instances, missing the minority class entirely."
            },
            {
                "f": "What is precision in classification?",
                "b": "The accuracy of positive predictions; the ratio of true positives to all positive predictions. Formula: Precision = TP / (TP + FP)"
            },
            {
                "f": "What is recall (sensitivity) in classification?",
                "b": "The ratio of positive instances that are correctly detected. Formula: Recall = TP / (TP + FN). Also called the true positive rate (TPR)."
            },
            {
                "f": "What is the F1 score?",
                "b": "The harmonic mean of precision and recall, providing a single score that balances both metrics. Formula: F1 = 2 × (precision × recall) / (precision + recall)"
            },
            {
                "f": "When will a classifier get a high F1 score?",
                "b": "Only when both precision and recall are high. The F1 score penalizes classifiers that have either low precision or low recall."
            },
            {
                "f": "What is specificity?",
                "b": "The true negative rate (TNR); the ratio of negative instances that are correctly identified as negative. Specificity = TN / (TN + FP)"
            },
            
            // Trade-offs
            {
                "f": "What is the precision/recall trade-off?",
                "b": "The inverse relationship where increasing precision typically reduces recall and vice versa. You can adjust this trade-off by changing the decision threshold."
            },
            {
                "f": "How does raising the decision threshold affect precision and recall?",
                "b": "It generally increases precision (fewer false positives) but decreases recall (more false negatives)."
            },
            {
                "f": "How does lowering the decision threshold affect precision and recall?",
                "b": "It generally decreases precision (more false positives) but increases recall (fewer false negatives)."
            },
            {
                "f": "When would you prioritize high precision over high recall?",
                "b": "When false positives are very costly (e.g., spam detection where legitimate emails must not be blocked, medical diagnosis where false alarms cause unnecessary worry)."
            },
            {
                "f": "When would you prioritize high recall over high precision?",
                "b": "When false negatives are very costly (e.g., fraud detection, disease screening, security threats where missing a positive case is dangerous)."
            },
            
            // ROC and AUC
            {
                "f": "What does the ROC (Receiver Operating Characteristic) curve plot?",
                "b": "It plots the True Positive Rate (TPR/Recall) against the False Positive Rate (FPR) at various threshold settings."
            },
            {
                "f": "What is the False Positive Rate (FPR)?",
                "b": "The ratio of negative instances incorrectly classified as positive. FPR = FP / (FP + TN) = 1 - Specificity"
            },
            {
                "f": "What does the Area Under the ROC Curve (AUC) measure?",
                "b": "A single-number summary of classifier performance. Perfect classifier: AUC = 1.0, Random classifier: AUC = 0.5, Worse than random: AUC < 0.5"
            },
            {
                "f": "When should you prefer the Precision-Recall curve over the ROC curve?",
                "b": "When dealing with highly imbalanced datasets where the positive class is rare, or when you care more about the performance on the positive class."
            },
            
            // Multiclass Strategies
            {
                "f": "What is the One-vs-Rest (OvR) strategy for multiclass classification?",
                "b": "Train one binary classifier for each class against all other classes combined, then select the class whose classifier outputs the highest confidence score."
            },
            {
                "f": "What is the One-vs-One (OvO) strategy for multiclass classification?",
                "b": "Train a binary classifier for every pair of classes, then classify by voting - the class that wins the most pairwise comparisons is selected."
            },
            {
                "f": "How many binary classifiers does OvO require for N classes?",
                "b": "N × (N-1) / 2 classifiers. For example, 10 classes would require 45 binary classifiers."
            },
            {
                "f": "What is the main advantage of the OvO strategy?",
                "b": "Each classifier only trains on data from two classes, making it faster for algorithms that don't scale well with dataset size, and potentially more accurate for complex decision boundaries."
            },
            
            // Advanced Classification Types
            {
                "f": "What is multilabel classification?",
                "b": "A classification system where each instance can belong to multiple classes simultaneously (e.g., tagging an article with multiple topics)."
            },
            {
                "f": "What is multioutput classification?",
                "b": "A generalization where each instance has multiple outputs, and each output can be multiclass (more than binary). Example: predicting multiple attributes of an object."
            },
            
            // Practical Techniques
            {
                "f": "What is data augmentation in the context of classification?",
                "b": "The technique of artificially expanding the training set by creating modified versions of existing data (e.g., rotating, scaling, or adding noise to images)."
            },
            {
                "f": "What is stratified sampling in cross-validation?",
                "b": "A sampling technique that ensures each fold contains approximately the same percentage of samples from each class as the complete dataset, maintaining class distribution."
            },
            {
                "f": "What is a key step in error analysis for a classifier?",
                "b": "Examining the confusion matrix to identify patterns in misclassification, understanding which classes are commonly confused with each other."
            },
            {
                "f": "How can you analyze errors in a multiclass confusion matrix?",
                "b": "Normalize by dividing each value by the number of instances in the actual class, then look for bright spots off the diagonal to identify common confusions."
            },
            {
                "f": "What is the effect of feature scaling on classification performance?",
                "b": "Proper feature scaling (e.g., standardization or normalization) often significantly improves classifier performance, especially for distance-based algorithms."
            },
            
            // Decision Functions
            {
                "f": "What is a decision function in classification?",
                "b": "A function that computes a score for each instance; the classifier assigns the instance to a class based on whether this score exceeds a threshold."
            },
            {
                "f": "What's the difference between decision_function() and predict_proba()?",
                "b": "decision_function() returns a score (can be any real number), while predict_proba() returns probability estimates between 0 and 1 for each class."
            },
            
            // Practical Considerations
            {
                "f": "Why might shuffling training data be beneficial?",
                "b": "It ensures that cross-validation folds are similar and prevents algorithms sensitive to instance order from learning spurious patterns."
            },
            {
                "f": "When should you NOT shuffle your training data?",
                "b": "For time series data or any sequential data where the order contains important information (e.g., stock prices, weather patterns, text sequences)."
            },
            {
                "f": "What are some ways to handle class imbalance?",
                "b": "Resampling (over-sampling minority or under-sampling majority), using class weights, choosing appropriate metrics (F1, AUC), or using ensemble methods like SMOTE."
            }
        ];

        let currentCard = 0;
        let isFlipped = false;

        function loadCard() {
            const card = flashcardsData[currentCard];
            document.getElementById('question').textContent = card.f;
            document.getElementById('answer').innerHTML = card.b.replace(/\$([^$]+)\$/g, '<em>$1</em>');
            document.getElementById('current').textContent = currentCard + 1;
            document.getElementById('total').textContent = flashcardsData.length;
            
            // Reset flip state
            isFlipped = false;
            document.getElementById('question').style.display = 'block';
            document.getElementById('answer').style.display = 'none';
            
            // Update button states
            document.getElementById('prevBtn').disabled = currentCard === 0;
            document.getElementById('nextBtn').disabled = currentCard === flashcardsData.length - 1;
        }

        function flipCard() {
            isFlipped = !isFlipped;
            if (isFlipped) {
                document.getElementById('question').style.display = 'none';
                document.getElementById('answer').style.display = 'block';
            } else {
                document.getElementById('question').style.display = 'block';
                document.getElementById('answer').style.display = 'none';
            }
        }

        function nextCard() {
            if (currentCard < flashcardsData.length - 1) {
                currentCard++;
                loadCard();
            }
        }

        function previousCard() {
            if (currentCard > 0) {
                currentCard--;
                loadCard();
            }
        }

        // Keyboard shortcuts
        document.addEventListener('keydown', function(event) {
            if (event.key === 'ArrowLeft') {
                previousCard();
            } else if (event.key === 'ArrowRight') {
                nextCard();
            } else if (event.key === ' ') {
                event.preventDefault();
                flipCard();
            }
        });

        // Initialize
        loadCard();
    </script>
</body>
</html>
